{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt+TPf7LVau3QxfsfOJvNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adnya-01/AI-projects/blob/main/semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Semantic Search**\n",
        "In this code, we'll walk through how semantic search can be used to find the most relevant searches to our query from a multilingual translation dataset.\n",
        "\n",
        "Semantic search refers to a retrieval method in which related search results are retrieved based on the context or the intent of the query, rather than just using keywords (as in lexical search).\n",
        "It can be used in applications where traditional lexical search is insufficient and the intent of the user's input is important as well as for multimodal and multilingual applications."
      ],
      "metadata": {
        "id": "hvGJ8XsljKIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries"
      ],
      "metadata": {
        "id": "MXPEDGJgny_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz8EPJzLg1RL"
      },
      "outputs": [],
      "source": [
        "!uv pip install -qU \\\n",
        "  pinecone~=7.3.0 \\\n",
        "  pinecone-notebooks==0.1.1 \\\n",
        "  numpy==2.0.2 \\\n",
        "  datasets==3.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate your Pinecone account and generate an API key"
      ],
      "metadata": {
        "id": "D6fbSTxtn2by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone_notebooks.colab import Authenticate\n",
        "\n",
        "Authenticate()"
      ],
      "metadata": {
        "id": "_3dNXeg3g4gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch your API key and initialize a Pinecone client which will be used to perform searches."
      ],
      "metadata": {
        "id": "fQxXulQ5sYp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "# Initialize client\n",
        "import os\n",
        "\n",
        "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "pc = Pinecone(\n",
        "        # You can remove this for your own projects!\n",
        "        api_key=api_key\n",
        "    )"
      ],
      "metadata": {
        "id": "3behv5tzhc5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create (if needed), connect to, and inspect a Pinecone semantic search index."
      ],
      "metadata": {
        "id": "GueejDfoutiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_name = \"semantic-search\"\n",
        "\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            \"model\": \"llama-text-embed-v2\",\n",
        "            \"field_map\":{\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Initialize index client\n",
        "index = pc.Index(name=index_name)\n",
        "\n",
        "# View index stats\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "MSZreVA_h0A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load English-Spanish translation sentence pairs from the Tatoeba dataset which contains thousands of sentence translation pairs."
      ],
      "metadata": {
        "id": "YLV9Xg2wwBcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# specify that we want the english-spanish translation pairs\n",
        "tatoeba = load_dataset(\"Helsinki-NLP/tatoeba\", lang1=\"en\", lang2=\"es\", trust_remote_code=True, split=\"train\")"
      ],
      "metadata": {
        "id": "wyQ8oTisiK4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tatoeba[0:5]"
      ],
      "metadata": {
        "id": "qQspHgCpiaN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords= [\"fan\"]\n",
        "\n",
        "def simple_keyword_filter(sentence, keywords):\n",
        "  # filter for a list of keywords by sentence\n",
        "\n",
        "    for keyword in keywords:\n",
        "        if keyword in sentence:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def transform_dataset_for_pinecone(dataset, use_filter=True):\n",
        "\n",
        "    if use_filter:\n",
        "        # filter for a list of keywords by sentence, helpful for building intuition on semantic search\n",
        "        translation_pairs = dataset.filter(lambda x: simple_keyword_filter(\n",
        "        sentence = x[\"translation\"][\"en\"], keywords=keywords))\n",
        "    else:\n",
        "        # use the full 200k+ dataset. Run only if you want to embed this many records!\n",
        "        translation_pairs = dataset\n",
        "\n",
        "    # flatten and shuffle for ease of use\n",
        "    translation_pairs = translation_pairs.flatten()\n",
        "    translation_pairs = translation_pairs.shuffle(seed=1)\n",
        "\n",
        "    english_sentences = translation_pairs.rename_column(\"translation.en\", \"text\").remove_columns(\"translation.es\")\n",
        "\n",
        "    # add lang column to indicate embedding origin\n",
        "    english_sentences = english_sentences.add_column(\"lang\", [\"en\"]*len(english_sentences))\n",
        "\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for idx, sentence in enumerate(english_sentences):\n",
        "        # Here, we create a record for each sentence in the dataset\n",
        "        # The record contains an ID and metadata fields which we can use to filter if desired\n",
        "        # The chunk_text field is the text we will embed\n",
        "        records.append(\n",
        "            {\n",
        "                \"id\": str(idx),\n",
        "                \"chunk_text\": sentence[\"text\"],\n",
        "                \"lang\": sentence[\"lang\"]\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # convert to record format\n",
        "    return records\n",
        "\n",
        "\n",
        "records = transform_dataset_for_pinecone(tatoeba)"
      ],
      "metadata": {
        "id": "sc0y0dz6iiPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 96\n",
        "namespace = \"english-sentences\"\n",
        "\n",
        "\n",
        "# We upsert in batches of 96 to avoid hitting the embedding model's rate limit.\n",
        "\n",
        "for start in tqdm(range(0, len(records), batch_size), f\"Upserting records batch: \"):\n",
        "    index.upsert_records(records=records[start:start+batch_size], namespace = namespace)"
      ],
      "metadata": {
        "id": "fS364eWCioMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"I am your biggest fan\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ],
      "metadata": {
        "id": "-Ymb7V0qis5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"We definately need a fan in this hot summer\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ],
      "metadata": {
        "id": "n-Qp3RHmiv7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"Stop fanning yourself\"\n",
        "\n",
        "results = index.search(\n",
        "    namespace=namespace,\n",
        "    query={\n",
        "        \"top_k\": 10,\n",
        "        \"inputs\": {\n",
        "            'text': search_query\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "for result in results[\"result\"][\"hits\"]:\n",
        "    print(f'Sentence: {result[\"fields\"][\"chunk_text\"]} Semantic Similarity Score: {result[\"_score\"]}\\n')"
      ],
      "metadata": {
        "id": "s5mlzu3d0tks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.delete_index(name=index_name)"
      ],
      "metadata": {
        "id": "Ajs_J1N6i3JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBQNMe59i_V4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}